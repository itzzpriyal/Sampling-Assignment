{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.cluster import KMeans\n"
      ],
      "metadata": {
        "id": "aP6uEFj6BGHU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "X = df.drop(\"Class\", axis=1)\n",
        "y = df[\"Class\"]\n",
        "\n",
        "print(\"Original class distribution:\")\n",
        "print(y.value_counts())\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9rKUNpsBGD4",
        "outputId": "38db3772-feee-485c-e32c-d6c41778d7fd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original class distribution:\n",
            "Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "n-gQLaRoBGBN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "train_df = pd.concat([X_train_bal, y_train_bal], axis=1)\n",
        "test_df = pd.concat([X_test, y_test], axis=1)\n"
      ],
      "metadata": {
        "id": "M3Eo88ARBF-X"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_random(df, frac=0.7):\n",
        "    return df.sample(frac=frac, random_state=42)\n",
        "\n",
        "def stratified(df, frac=0.7):\n",
        "    return df.groupby(\"Class\", group_keys=False).sample(frac=frac, random_state=42)\n",
        "\n",
        "def systematic(df, step=2):\n",
        "    return df.iloc[::step]\n",
        "\n",
        "def cluster(df, k=6, choose=3):\n",
        "    X_feat = df.drop(\"Class\", axis=1)\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    temp = df.copy()\n",
        "    temp[\"cluster\"] = km.fit_predict(X_feat)\n",
        "    selected = np.random.choice(temp[\"cluster\"].unique(), choose, replace=False)\n",
        "    return temp[temp[\"cluster\"].isin(selected)].drop(\"cluster\", axis=1)\n",
        "\n",
        "def full_smote(df):\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "8k3uE9RNBF73"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = {\n",
        "    \"Sampling1\": simple_random(train_df),\n",
        "    \"Sampling2\": stratified(train_df),\n",
        "    \"Sampling3\": systematic(train_df),\n",
        "    \"Sampling4\": cluster(train_df),\n",
        "    \"Sampling5\": full_smote(train_df)\n",
        "}\n"
      ],
      "metadata": {
        "id": "ZdXbu2GxBF5b"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"M1\": LogisticRegression(max_iter=2000),\n",
        "    \"M2\": DecisionTreeClassifier(max_depth=5),\n",
        "    \"M3\": RandomForestClassifier(n_estimators=80, max_depth=6),\n",
        "    \"M4\": KNeighborsClassifier(n_neighbors=7),\n",
        "    \"M5\": GaussianNB()\n",
        "}\n"
      ],
      "metadata": {
        "id": "W21-19OlBF2y"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(index=models.keys(), columns=samples.keys())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_test_scaled = scaler.fit_transform(test_df.drop(\"Class\", axis=1))\n",
        "y_test = test_df[\"Class\"]\n",
        "\n",
        "for samp_name, samp_df in samples.items():\n",
        "    X_train = samp_df.drop(\"Class\", axis=1)\n",
        "    y_train = samp_df[\"Class\"]\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        if model_name in [\"M1\", \"M4\"]:\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            preds = model.predict(X_test_scaled)\n",
        "        else:\n",
        "            model.fit(X_train, y_train)\n",
        "            preds = model.predict(X_test)\n",
        "\n",
        "        acc = accuracy_score(y_test, preds) * 100\n",
        "        results.loc[model_name, samp_name] = round(acc, 2)\n"
      ],
      "metadata": {
        "id": "Y_M8aWWuBR6p"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ACCURACY RESULTS TABLE (%)\")\n",
        "print(results)\n",
        "\n",
        "print(\"\\nBEST SAMPLING TECHNIQUE FOR EACH MODEL\")\n",
        "best = results.astype(float).idxmax(axis=1)\n",
        "\n",
        "for m in results.index:\n",
        "    print(f\"{m}: {best[m]} ({results.loc[m, best[m]]}%)\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znQeINeTBT3j",
        "outputId": "ea3a5df9-db39-446e-8932-a6a375fbd4c3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY RESULTS TABLE (%)\n",
            "   Sampling1 Sampling2 Sampling3 Sampling4 Sampling5\n",
            "M1     56.47     59.48     48.28     60.34     54.74\n",
            "M2     93.53     90.52     90.52      93.1     90.95\n",
            "M3     98.71     98.71     98.28     98.71     98.28\n",
            "M4     77.59     73.28     72.84     83.62     81.47\n",
            "M5     96.12     96.55     96.98      94.4     95.26\n",
            "\n",
            "BEST SAMPLING TECHNIQUE FOR EACH MODEL\n",
            "M1: Sampling4 (60.34%)\n",
            "M2: Sampling1 (93.53%)\n",
            "M3: Sampling1 (98.71%)\n",
            "M4: Sampling4 (83.62%)\n",
            "M5: Sampling3 (96.98%)\n"
          ]
        }
      ]
    }
  ]
}